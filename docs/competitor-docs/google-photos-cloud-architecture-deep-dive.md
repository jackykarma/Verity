# Google Photos äº‘ç«¯æ¶æ„æ·±åº¦æŠ€æœ¯è§£æ

> æŠ€æœ¯åˆ†ææ—¥æœŸï¼š2026-01-28  
> åˆ†æå¯¹è±¡ï¼šGoogle Photos Cloud-Based Architecture  
> æŠ€æœ¯æ ˆï¼šSpanner + Cloud Vision API + FaceNet + Gemini + Dataflow

---

## ä¸€ã€äº‘ç«¯æ¶æ„æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯äº‘ç«¯æ¶æ„

Google Photos é‡‡ç”¨**å®Œå…¨äº‘ç«¯å¤„ç†æ¶æ„**ï¼Œæ‰€æœ‰è®¡ç®—å¯†é›†å‹ä»»åŠ¡ï¼ˆæœºå™¨å­¦ä¹ ã€å›¾åƒåˆ†æã€è§†é¢‘ç”Ÿæˆï¼‰éƒ½åœ¨ Google Cloud çš„æ•°æ®ä¸­å¿ƒå®Œæˆã€‚å®¢æˆ·ç«¯ï¼ˆAppï¼‰ä¸»è¦è´Ÿè´£ä¸Šä¼ ç…§ç‰‡ã€å±•ç¤ºç»“æœå’Œç”¨æˆ·äº¤äº’ã€‚

### 1.2 æ ¸å¿ƒç‰¹ç‚¹

| ç‰¹æ€§ | è¯´æ˜ | æŠ€æœ¯ä¼˜åŠ¿ |
|-----|------|---------|
| **æ— é™ç®—åŠ›** | Google æ•°æ®ä¸­å¿ƒåˆ†å¸ƒå¼è®¡ç®— | å¤„ç†èƒ½åŠ›æ— ä¸Šé™ |
| **å¤§è§„æ¨¡æ•°æ®** | 40+ äº¿å¼ ç…§ç‰‡ï¼Œ10+ äº¿ç”¨æˆ· | è§„æ¨¡åŒ–è®­ç»ƒä¼˜åŠ¿ |
| **è·¨è®¾å¤‡åŒæ­¥** | å¤šè®¾å¤‡æ— ç¼è®¿é—® | æ•°æ®æ°¸ä¸ä¸¢å¤± |
| **æŒç»­è¿›åŒ–** | äº‘ç«¯æ¨¡å‹å¿«é€Ÿè¿­ä»£ | æ— éœ€å®¢æˆ·ç«¯æ›´æ–° |
| **å¤æ‚åŠŸèƒ½** | æ”¯æŒé«˜çº§ AI ç‰¹æ€§ | ç”µå½±æ•ˆæœã€NLP ç”Ÿæˆ |

**æœåŠ¡è§„æ¨¡ï¼ˆ2024 å¹´æ•°æ®ï¼‰**
- ç”¨æˆ·æ•°ï¼š10 äº¿+
- ç…§ç‰‡/è§†é¢‘æ€»é‡ï¼š40 äº¿+ï¼ˆ4 trillionï¼‰
- æ—¥å‡ä¸Šä¼ é‡ï¼š60 äº¿å¼ ç…§ç‰‡
- æœˆæ´»æœç´¢ç”¨æˆ·ï¼š5 äº¿

---

## äºŒã€äº‘ç«¯æŠ€æœ¯æ¶æ„è¯¦è§£

### 2.1 æ•´ä½“æ¶æ„å›¾

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    subgraph Client["å®¢æˆ·ç«¯å±‚"]
        AndroidApp["Android App"]
        iOSApp["iOS App"]
        WebApp["Web App"]
    end
    
    subgraph Gateway["æ¥å…¥å±‚"]
        LoadBalancer["å…¨çƒè´Ÿè½½å‡è¡¡"]
        APIGateway["API ç½‘å…³"]
        Auth["èº«ä»½è®¤è¯"]
    end
    
    subgraph Services["æœåŠ¡å±‚ (æ•°åä¸ªå¾®æœåŠ¡)"]
        UploadService["ä¸Šä¼ æœåŠ¡"]
        DownloadService["ä¸‹è½½æœåŠ¡"]
        SearchService["æœç´¢æœåŠ¡"]
        AlbumService["ç›¸å†ŒæœåŠ¡"]
        MemoryService["å›å¿†æœåŠ¡"]
        SharingService["åˆ†äº«æœåŠ¡"]
    end
    
    subgraph ML["æœºå™¨å­¦ä¹ å±‚"]
        VisionAPI["Cloud Vision API"]
        FaceNet["FaceNet äººè„¸è¯†åˆ«"]
        DepthEstimation["æ·±åº¦ä¼°è®¡ç½‘ç»œ"]
        Gemini["Gemini NLP"]
        VideoGen["è§†é¢‘ç”Ÿæˆ"]
    end
    
    subgraph Processing["æ‰¹å¤„ç†å±‚"]
        Dataflow["Dataflow æµæ°´çº¿"]
        PubSub["Pub/Sub æ¶ˆæ¯é˜Ÿåˆ—"]
        BatchJobs["æ‰¹å¤„ç†ä½œä¸š"]
    end
    
    subgraph Data["æ•°æ®å±‚"]
        Spanner["Cloud Spanner<br/>(å…ƒæ•°æ®)"]
        CloudStorage["Cloud Storage<br/>(åŸå§‹æ–‡ä»¶)"]
        BigQuery["BigQuery<br/>(åˆ†ææ•°æ®)"]
        Memcache["Memcache<br/>(ç¼“å­˜)"]
    end
    
    AndroidApp --> LoadBalancer
    iOSApp --> LoadBalancer
    WebApp --> LoadBalancer
    
    LoadBalancer --> APIGateway
    APIGateway --> Auth
    
    Auth --> UploadService
    Auth --> DownloadService
    Auth --> SearchService
    Auth --> AlbumService
    Auth --> MemoryService
    Auth --> SharingService
    
    UploadService --> CloudStorage
    UploadService --> PubSub
    
    PubSub --> Dataflow
    Dataflow --> VisionAPI
    Dataflow --> FaceNet
    Dataflow --> DepthEstimation
    
    VisionAPI --> Spanner
    FaceNet --> Spanner
    DepthEstimation --> Spanner
    
    SearchService --> Gemini
    Gemini --> Spanner
    
    MemoryService --> VideoGen
    VideoGen --> CloudStorage
    
    Spanner --> Memcache
    
    BatchJobs --> BigQuery
    BigQuery --> Spanner

    style Client fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Gateway fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Services fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style ML fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Processing fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Data fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
```

### 2.2 æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶

#### 2.2.1 Cloud Spanner - å…¨çƒåˆ†å¸ƒå¼æ•°æ®åº“

**æŠ€æœ¯ç‰¹ç‚¹**
- å…¨çƒä¸€è‡´æ€§çš„ SQL æ•°æ®åº“
- 99.999% å¯ç”¨æ€§ï¼ˆæ¯å¹´åœæœº < 5.26 åˆ†é’Ÿï¼‰
- æ¯ç§’å¤„ç† 100 ä¸‡æ¬¡è¯»æŸ¥è¯¢
- P99 å»¶è¿Ÿ < 300ms

**æ¶æ„åˆ›æ–°ï¼šçªç ´ CAP å®šç†**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart LR
    subgraph Traditional["ä¼ ç»Ÿ CAP å®šç†"]
        CAP["åªèƒ½é€‰ä¸¤ä¸ª:<br/>C (ä¸€è‡´æ€§)<br/>A (å¯ç”¨æ€§)<br/>P (åˆ†åŒºå®¹é”™)"]
    end
    
    subgraph Spanner["Spanner æ–¹æ¡ˆ"]
        TrueTime["TrueTime<br/>(å…¨çƒæ—¶é’ŸåŒæ­¥)"]
        PrivateNet["Google ç§æœ‰ç½‘ç»œ<br/>(é«˜å¯é æ€§)"]
        Replication["å¤šå‰¯æœ¬å¤åˆ¶<br/>(å…¨çƒåˆ†å¸ƒ)"]
    end
    
    subgraph Result["å®é™…æ•ˆæœ"]
        CP["ç†è®º: CP ç³»ç»Ÿ"]
        CA["å®è·µ: äº‹å®ä¸Šçš„ CA<br/>(å¯ç”¨æ€§ 99.999%)"]
    end
    
    Traditional --> Spanner
    TrueTime --> Result
    PrivateNet --> Result
    Replication --> Result
    
    CP -.->|æé«˜å¯ç”¨æ€§| CA

    style Traditional fill:#FFEBEE,stroke:#D32F2F,stroke-width:2px
    style Spanner fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Result fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
```

**TrueTime æŠ€æœ¯**

TrueTime æ˜¯ Google çš„å…¨çƒåŒæ­¥æ—¶é’Ÿç³»ç»Ÿï¼Œä¸ºæ¯ä¸ªæ•°æ®ä¸­å¿ƒæä¾›ç²¾ç¡®çš„æ—¶é—´æˆ³ã€‚

```python
# TrueTime API ä¼ªä»£ç 
class TrueTime:
    def now(self) -> TimeInterval:
        """è¿”å›å½“å‰æ—¶é—´åŒºé—´ [earliest, latest]"""
        # é€šè¿‡ GPS + åŸå­é’Ÿ è·å–æ—¶é—´
        # è€ƒè™‘æ—¶é’Ÿæ¼‚ç§»å’Œç½‘ç»œå»¶è¿Ÿ
        return TimeInterval(earliest, latest)
    
    def after(self, t: Timestamp) -> bool:
        """å½“å‰æ—¶é—´æ˜¯å¦ç»å¯¹åœ¨ t ä¹‹å"""
        return self.now().earliest > t
    
    def before(self, t: Timestamp) -> bool:
        """å½“å‰æ—¶é—´æ˜¯å¦ç»å¯¹åœ¨ t ä¹‹å‰"""
        return self.now().latest < t

# Spanner äº‹åŠ¡å®ç°
class SpannerTransaction:
    def commit(self):
        # 1. è·å–æäº¤æ—¶é—´æˆ³
        commit_timestamp = TrueTime.now().latest
        
        # 2. ç­‰å¾…ç›´åˆ°ç¡®ä¿æ—¶é—´æˆ³å”¯ä¸€æ€§
        TrueTime.wait_until_after(commit_timestamp)
        
        # 3. å†™å…¥æ•°æ®
        self.write_data_with_timestamp(commit_timestamp)
        
        # 4. å…¨çƒä¸€è‡´æ€§ä¿è¯
        # ä»»ä½•åç»­è¯»å–éƒ½èƒ½çœ‹åˆ°æ­¤æ¬¡æäº¤
```

**æ•°æ®åˆ†ç‰‡ä¸å¤åˆ¶**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    subgraph Global["å…¨çƒæ•°æ®åˆ†å¸ƒ"]
        US["ç¾å›½æ•°æ®ä¸­å¿ƒ"]
        EU["æ¬§æ´²æ•°æ®ä¸­å¿ƒ"]
        ASIA["äºšæ´²æ•°æ®ä¸­å¿ƒ"]
    end
    
    subgraph Sharding["æ•°æ®åˆ†ç‰‡ç­–ç•¥"]
        UserShard1["ç”¨æˆ·åˆ†ç‰‡ 1<br/>(UID 0-1000ä¸‡)"]
        UserShard2["ç”¨æˆ·åˆ†ç‰‡ 2<br/>(UID 1000ä¸‡-2000ä¸‡)"]
        UserShardN["ç”¨æˆ·åˆ†ç‰‡ N<br/>(UID N)"]
    end
    
    subgraph Replication["å‰¯æœ¬ç­–ç•¥"]
        Primary["ä¸»å‰¯æœ¬<br/>(è¯»å†™)"]
        Replica1["å‰¯æœ¬ 1<br/>(åªè¯»)"]
        Replica2["å‰¯æœ¬ 2<br/>(åªè¯»)"]
    end
    
    US --> UserShard1
    EU --> UserShard2
    ASIA --> UserShardN
    
    UserShard1 --> Primary
    Primary --> Replica1
    Primary --> Replica2
    
    Replica1 -.->|å¼‚æ­¥å¤åˆ¶| US
    Replica2 -.->|å¼‚æ­¥å¤åˆ¶| EU

    style Global fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Sharding fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Replication fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
```

**æ•°æ®æ¨¡å‹**

```sql
-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    user_id STRING(36) NOT NULL,
    email STRING(256),
    display_name STRING(128),
    storage_quota BIGINT,
    created_at TIMESTAMP,
    PRIMARY KEY (user_id)
);

-- ç…§ç‰‡å…ƒæ•°æ®è¡¨ï¼ˆæ ¸å¿ƒè¡¨ï¼‰
CREATE TABLE photos (
    photo_id STRING(36) NOT NULL,
    user_id STRING(36) NOT NULL,
    file_path STRING(512),
    storage_bucket STRING(64),
    upload_timestamp TIMESTAMP,
    capture_timestamp TIMESTAMP,
    latitude FLOAT64,
    longitude FLOAT64,
    width INT64,
    height INT64,
    file_size BIGINT,
    mime_type STRING(64),
    PRIMARY KEY (user_id, photo_id),
    INTERLEAVE IN PARENT users ON DELETE CASCADE
) PRIMARY KEY (user_id, photo_id);

-- æœºå™¨å­¦ä¹ æ ‡ç­¾è¡¨
CREATE TABLE photo_labels (
    photo_id STRING(36) NOT NULL,
    user_id STRING(36) NOT NULL,
    label_name STRING(128),
    label_category STRING(64),
    confidence FLOAT64,
    source STRING(32), -- 'vision_api', 'custom_model'
    created_at TIMESTAMP,
    PRIMARY KEY (user_id, photo_id, label_name),
    INTERLEAVE IN PARENT photos ON DELETE CASCADE
);

-- äººè„¸è¯†åˆ«è¡¨
CREATE TABLE faces (
    face_id STRING(36) NOT NULL,
    user_id STRING(36) NOT NULL,
    photo_id STRING(36) NOT NULL,
    person_cluster_id STRING(36),
    embedding ARRAY<FLOAT64>, -- 128 ç»´ç‰¹å¾å‘é‡
    bbox_x FLOAT64,
    bbox_y FLOAT64,
    bbox_width FLOAT64,
    bbox_height FLOAT64,
    confidence FLOAT64,
    PRIMARY KEY (user_id, face_id),
    INTERLEAVE IN PARENT users ON DELETE CASCADE
);

-- äººç‰©èšç±»è¡¨
CREATE TABLE person_clusters (
    cluster_id STRING(36) NOT NULL,
    user_id STRING(36) NOT NULL,
    display_name STRING(128),
    face_count INT64,
    representative_face_id STRING(36),
    is_favorite BOOL,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    PRIMARY KEY (user_id, cluster_id),
    INTERLEAVE IN PARENT users ON DELETE CASCADE
);

-- å›å¿†è¡¨
CREATE TABLE memories (
    memory_id STRING(36) NOT NULL,
    user_id STRING(36) NOT NULL,
    memory_type STRING(32), -- 'travel', 'people', 'place', 'anniversary'
    title STRING(256),
    description TEXT,
    start_date DATE,
    end_date DATE,
    photo_ids ARRAY<STRING(36)>,
    video_url STRING(512),
    generation_timestamp TIMESTAMP,
    view_count INT64,
    PRIMARY KEY (user_id, memory_id),
    INTERLEAVE IN PARENT users ON DELETE CASCADE
);

-- æœç´¢ç´¢å¼•è¡¨
CREATE TABLE search_index (
    user_id STRING(36) NOT NULL,
    photo_id STRING(36) NOT NULL,
    search_text TEXT, -- åŒ…å«æ‰€æœ‰æ ‡ç­¾ã€äººç‰©åã€åœ°ç‚¹çš„å…¨æ–‡ç´¢å¼•
    embedding ARRAY<FLOAT64>, -- CLIP é£æ ¼çš„å¤šæ¨¡æ€åµŒå…¥
    PRIMARY KEY (user_id, photo_id)
);
```

**æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯**

| æŠ€æœ¯ | è¯´æ˜ | æ•ˆæœ |
|-----|------|------|
| **INTERLEAVE** | å­è¡¨æ•°æ®ä¸çˆ¶è¡¨å…±å­˜ | å‡å°‘è·¨èŠ‚ç‚¹æŸ¥è¯¢ |
| **åˆ†ç‰‡ç­–ç•¥** | æŒ‰ user_id åˆ†ç‰‡ | ç”¨æˆ·æ•°æ®å±€éƒ¨æ€§ |
| **å‰¯æœ¬æ”¾ç½®** | å…¨çƒå¤šå‰¯æœ¬ | å°±è¿‘è¯»å–ï¼Œä½å»¶è¿Ÿ |
| **æ‰¹é‡æäº¤** | äº‹åŠ¡æ‰¹å¤„ç† | ååé‡ â†‘ 10x |
| **æŸ¥è¯¢ä¼˜åŒ–** | ç´¢å¼• + ç¼“å­˜ | æŸ¥è¯¢å»¶è¿Ÿ â†“ 50% |

#### 2.2.2 Cloud Storage - æµ·é‡æ–‡ä»¶å­˜å‚¨

**å­˜å‚¨æ¶æ„**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    subgraph Upload["ä¸Šä¼ æµç¨‹"]
        Client["å®¢æˆ·ç«¯"]
        Compress["æ™ºèƒ½å‹ç¼©<br/>(WebP/AVIF)"]
        MultiPart["åˆ†ç‰‡ä¸Šä¼ <br/>(å¤§æ–‡ä»¶)"]
    end
    
    subgraph Storage["å­˜å‚¨å±‚çº§"]
        Hot["çƒ­å­˜å‚¨<br/>(30å¤©å†…)"]
        Nearline["è¿‘çº¿å­˜å‚¨<br/>(30-90å¤©)"]
        Coldline["å†·çº¿å­˜å‚¨<br/>(90-365å¤©)"]
        Archive["å½’æ¡£å­˜å‚¨<br/>(365å¤©+)"]
    end
    
    subgraph Optimization["ä¼˜åŒ–æŠ€æœ¯"]
        Dedupe["å»é‡<br/>(SHA256)"]
        CDN["å…¨çƒ CDN åŠ é€Ÿ"]
        LazyLoad["æ‡’åŠ è½½ç¼©ç•¥å›¾"]
    end
    
    Client --> Compress
    Compress --> MultiPart
    
    MultiPart --> Hot
    Hot -->|è‡ªåŠ¨é™çº§| Nearline
    Nearline -->|è‡ªåŠ¨é™çº§| Coldline
    Coldline -->|è‡ªåŠ¨é™çº§| Archive
    
    Hot --> Dedupe
    Dedupe --> CDN
    CDN --> LazyLoad

    style Upload fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Storage fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Optimization fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
```

**å›¾åƒå‹ç¼©ç­–ç•¥**

| æ ¼å¼ | å‹ç¼©æ¯” | è´¨é‡ | ç”¨é€” |
|-----|-------|------|------|
| **åŸå§‹æ ¼å¼** | 0% | 100% | ç”¨æˆ·åŸå§‹ä¸Šä¼  |
| **AVIF** | 60% vs JPEG | 95% | é«˜è´¨é‡å±•ç¤º |
| **WebP** | 30% vs PNG | 90% | æ ‡å‡†å±•ç¤º |
| **JPEG (é«˜è´¨é‡)** | 20% | 85% | å…¼å®¹æ€§å±•ç¤º |
| **ç¼©ç•¥å›¾** | 90% | 70% | åˆ—è¡¨å±•ç¤º |

**æ–‡ä»¶å»é‡æŠ€æœ¯**

```python
# æ–‡ä»¶å»é‡ä¼ªä»£ç 
class FileDeduplication:
    def upload_photo(self, user_id, file_data):
        # 1. è®¡ç®— SHA256 å“ˆå¸Œ
        file_hash = sha256(file_data)
        
        # 2. æ£€æŸ¥å…¨å±€å»é‡è¡¨
        existing_file = check_global_hash_table(file_hash)
        
        if existing_file:
            # 3. æ–‡ä»¶å·²å­˜åœ¨ï¼Œåªå­˜å‚¨å¼•ç”¨
            create_reference(user_id, existing_file.path)
            return existing_file.path
        else:
            # 4. æ–°æ–‡ä»¶ï¼Œå­˜å‚¨åˆ° Cloud Storage
            file_path = store_to_cloud_storage(file_data)
            
            # 5. æ›´æ–°å…¨å±€å“ˆå¸Œè¡¨
            add_to_global_hash_table(file_hash, file_path)
            
            # 6. åˆ›å»ºç”¨æˆ·å¼•ç”¨
            create_reference(user_id, file_path)
            
            return file_path
```

**å­˜å‚¨æˆæœ¬ä¼˜åŒ–**

```
åŸå§‹ç­–ç•¥ï¼ˆæ— ä¼˜åŒ–ï¼‰:
- 10 äº¿ç”¨æˆ·ï¼Œå¹³å‡æ¯äºº 1000 å¼ ç…§ç‰‡ï¼Œæ¯å¼  3MB
- æ€»å­˜å‚¨: 10^9 Ã— 1000 Ã— 3MB = 3 EB (è‰¾å­—èŠ‚)
- æˆæœ¬: $3,000,000,000/å¹´ (æŒ‰ $0.001/GB/æœˆ)

ä¼˜åŒ–å:
- å‹ç¼© 60% â†’ 1.2 EB
- å»é‡ 20% â†’ 0.96 EB
- åˆ†å±‚å­˜å‚¨ 40% â†’ 0.576 EB
- æˆæœ¬: $576,000,000/å¹´
- èŠ‚çœ: 81%
```

#### 2.2.3 Pub/Sub + Dataflow - æ‰¹å¤„ç†æµæ°´çº¿

**å¼‚æ­¥å¤„ç†æ¶æ„**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'actorBkg': '#E3F2FD', 'actorBorder': '#1976D2', 'actorTextColor': '#1565C0', 'signalColor': '#1976D2', 'signalTextColor': '#212121', 'noteBkgColor': '#FFF8E1', 'noteBorderColor': '#FFC107'}}}%%
sequenceDiagram
    autonumber
    
    participant User as ç”¨æˆ·
    participant App as Photos App
    participant Storage as Cloud Storage
    participant PubSub as Pub/Sub
    participant Dataflow as Dataflow
    participant ML as ML æœåŠ¡
    participant Spanner as Spanner

    User->>App: ä¸Šä¼ ç…§ç‰‡
    App->>Storage: å­˜å‚¨åŸå§‹æ–‡ä»¶
    Storage-->>App: è¿”å›æ–‡ä»¶è·¯å¾„
    
    Storage->>PubSub: å‘å¸ƒä¸Šä¼ äº‹ä»¶
    Note over PubSub: äº‹ä»¶: PHOTO_UPLOADED<br/>user_id, photo_id, path
    
    PubSub->>Dataflow: è§¦å‘æµæ°´çº¿
    
    par å¹¶è¡Œå¤„ç†
        Dataflow->>ML: Vision API (æ ‡ç­¾æ£€æµ‹)
        Dataflow->>ML: FaceNet (äººè„¸è¯†åˆ«)
        Dataflow->>ML: æ·±åº¦ä¼°è®¡ (ç”µå½±æ•ˆæœ)
        Dataflow->>ML: ç¼©ç•¥å›¾ç”Ÿæˆ
    end
    
    ML-->>Dataflow: è¿”å›åˆ†æç»“æœ
    
    Dataflow->>Spanner: æ‰¹é‡å†™å…¥å…ƒæ•°æ®
    Spanner-->>Dataflow: ç¡®è®¤å†™å…¥
    
    Dataflow->>PubSub: å‘å¸ƒå®Œæˆäº‹ä»¶
    PubSub->>App: æ¨é€é€šçŸ¥
    App-->>User: ç…§ç‰‡åˆ†æå®Œæˆ
```

**Dataflow æµæ°´çº¿é…ç½®**

```python
# Apache Beam + Dataflow ä¼ªä»£ç 
import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions

class PhotoProcessingPipeline:
    def run(self):
        options = PipelineOptions(
            runner='DataflowRunner',
            project='google-photos',
            region='us-central1',
            temp_location='gs://temp-bucket',
            max_num_workers=1000,
            autoscaling_algorithm='THROUGHPUT_BASED'
        )
        
        with beam.Pipeline(options=options) as pipeline:
            (pipeline
                # 1. è¯»å– Pub/Sub æ¶ˆæ¯
                | 'Read from Pub/Sub' >> beam.io.ReadFromPubSub(
                    topic='projects/google-photos/topics/photo-uploads'
                )
                
                # 2. è§£ææ¶ˆæ¯
                | 'Parse JSON' >> beam.Map(parse_photo_event)
                
                # 3. å¹¶è¡Œå¤„ç†
                | 'Process Photos' >> beam.ParDo(ProcessPhoto())
                
                # 4. æ‰¹é‡å†™å…¥ Spanner
                | 'Write to Spanner' >> beam.io.WriteToSpanner(
                    instance='photos-prod',
                    database='photos',
                    table='photo_labels',
                    batch_size=1000
                )
            )

class ProcessPhoto(beam.DoFn):
    def process(self, element):
        photo_id = element['photo_id']
        file_path = element['file_path']
        
        # å¹¶è¡Œè°ƒç”¨å¤šä¸ª ML æœåŠ¡
        vision_labels = self.call_vision_api(file_path)
        faces = self.call_facenet(file_path)
        depth_map = self.call_depth_estimation(file_path)
        
        # è¿”å›ç»“æœ
        yield {
            'photo_id': photo_id,
            'labels': vision_labels,
            'faces': faces,
            'depth_map': depth_map,
            'processed_at': datetime.now()
        }
```

**æµæ°´çº¿æ€§èƒ½**

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|-----|------|------|
| **ååé‡** | 60 äº¿å¼ /å¤© | æ—¥å‡ä¸Šä¼ é‡ |
| **å¹¶å‘åº¦** | 1000+ å·¥ä½œèŠ‚ç‚¹ | åŠ¨æ€ä¼¸ç¼© |
| **å»¶è¿Ÿ** | < 5 ç§’ | ä¸Šä¼ åˆ°å®Œæˆåˆ†æ |
| **æˆæœ¬** | æŒ‰é‡è®¡è´¹ | æ— é—²ç½®èµ„æº |

---

## ä¸‰ã€æ ¸å¿ƒæœºå™¨å­¦ä¹ æŠ€æœ¯

### 3.1 FaceNet - äººè„¸è¯†åˆ«

**æŠ€æœ¯åŸç†**

FaceNet æ˜¯ Google åœ¨ 2015 å¹´æå‡ºçš„æ·±åº¦å­¦ä¹ äººè„¸è¯†åˆ«ç³»ç»Ÿï¼Œä½¿ç”¨ä¸‰å…ƒç»„æŸå¤±ï¼ˆTriplet Lossï¼‰è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œã€‚

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart LR
    subgraph Input["è¾“å…¥ä¸‰å…ƒç»„"]
        Anchor["é”šç‚¹<br/>(äººç‰© A)"]
        Positive["æ­£æ ·æœ¬<br/>(äººç‰© A)"]
        Negative["è´Ÿæ ·æœ¬<br/>(äººç‰© B)"]
    end
    
    subgraph CNN["å·ç§¯ç¥ç»ç½‘ç»œ"]
        Conv1["å·ç§¯å±‚ 1-5"]
        Conv2["Inception æ¨¡å—"]
        FC["å…¨è¿æ¥å±‚"]
    end
    
    subgraph Embedding["åµŒå…¥ç©ºé—´"]
        E_Anchor["å‘é‡ A<br/>(128 ç»´)"]
        E_Positive["å‘é‡ A'<br/>(128 ç»´)"]
        E_Negative["å‘é‡ B<br/>(128 ç»´)"]
    end
    
    subgraph Loss["ä¸‰å…ƒç»„æŸå¤±"]
        Distance["è·ç¦»è®¡ç®—"]
        TripletLoss["Loss = max(0, d(A,A') - d(A,B) + margin)"]
    end
    
    Anchor --> Conv1
    Positive --> Conv1
    Negative --> Conv1
    
    Conv1 --> Conv2
    Conv2 --> FC
    
    FC --> E_Anchor
    FC --> E_Positive
    FC --> E_Negative
    
    E_Anchor --> Distance
    E_Positive --> Distance
    E_Negative --> Distance
    
    Distance --> TripletLoss

    style Input fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style CNN fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Embedding fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style Loss fill:#FFEBEE,stroke:#D32F2F,stroke-width:2px
```

**ä¸‰å…ƒç»„æŸå¤±å‡½æ•°**

```python
def triplet_loss(anchor, positive, negative, margin=0.2):
    """
    ä¸‰å…ƒç»„æŸå¤±å‡½æ•°
    
    ç›®æ ‡ï¼šè®©åŒä¸€äººçš„ç…§ç‰‡è·ç¦»è¿‘ï¼Œä¸åŒäººçš„ç…§ç‰‡è·ç¦»è¿œ
    """
    # è®¡ç®— L2 è·ç¦»
    d_pos = euclidean_distance(anchor, positive)
    d_neg = euclidean_distance(anchor, negative)
    
    # æŸå¤±å‡½æ•°
    loss = max(0, d_pos - d_neg + margin)
    
    return loss

def euclidean_distance(x, y):
    """æ¬§æ°è·ç¦»"""
    return np.sqrt(np.sum((x - y) ** 2))
```

**åœ¨çº¿ä¸‰å…ƒç»„æŒ–æ˜**

FaceNet çš„åˆ›æ–°åœ¨äºåœ¨çº¿æŒ–æ˜å›°éš¾æ ·æœ¬ï¼ˆHard Triplet Miningï¼‰ã€‚

```python
class OnlineTripletMining:
    def select_triplets(self, batch_embeddings, batch_labels):
        """
        ä»æ‰¹æ¬¡ä¸­é€‰æ‹©å›°éš¾ä¸‰å…ƒç»„
        """
        triplets = []
        
        for i, anchor_label in enumerate(batch_labels):
            anchor_embedding = batch_embeddings[i]
            
            # 1. æ‰¾åˆ°æœ€å›°éš¾çš„æ­£æ ·æœ¬ï¼ˆè·ç¦»æœ€è¿œçš„åŒç±»ï¼‰
            positive_indices = np.where(batch_labels == anchor_label)[0]
            positive_indices = positive_indices[positive_indices != i]
            
            if len(positive_indices) == 0:
                continue
            
            positive_distances = [
                euclidean_distance(anchor_embedding, batch_embeddings[j])
                for j in positive_indices
            ]
            hardest_positive_idx = positive_indices[np.argmax(positive_distances)]
            
            # 2. æ‰¾åˆ°æœ€å›°éš¾çš„è´Ÿæ ·æœ¬ï¼ˆè·ç¦»æœ€è¿‘çš„å¼‚ç±»ï¼‰
            negative_indices = np.where(batch_labels != anchor_label)[0]
            negative_distances = [
                euclidean_distance(anchor_embedding, batch_embeddings[j])
                for j in negative_indices
            ]
            hardest_negative_idx = negative_indices[np.argmin(negative_distances)]
            
            # 3. ç»„æˆä¸‰å…ƒç»„
            triplets.append((i, hardest_positive_idx, hardest_negative_idx))
        
        return triplets
```

**æ€§èƒ½æŒ‡æ ‡**

| æ•°æ®é›† | å‡†ç¡®ç‡ | è¯¯è¯†ç‡ (FAR) | è¯´æ˜ |
|-------|-------|-------------|------|
| **LFW** | 99.63% | 0.37% | æ ‡å‡†äººè„¸è¯†åˆ«åŸºå‡† |
| **YouTube Faces** | 95.12% | 4.88% | è§†é¢‘äººè„¸è¯†åˆ« |
| **ç‰¹å¾ç»´åº¦** | 128 ç»´ | - | æ¯å¼ äººè„¸ä»… 128 å­—èŠ‚ |

**äººç‰©èšç±»æµç¨‹**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    Start([æ–°ç…§ç‰‡ä¸Šä¼ ]) --> FaceDetect[äººè„¸æ£€æµ‹<br/>(æ£€æµ‹è¾¹ç•Œæ¡†)]
    
    FaceDetect --> Extract[æå–äººè„¸åŒºåŸŸ]
    Extract --> FaceNet[FaceNet ç‰¹å¾æå–<br/>(128 ç»´å‘é‡)]
    
    FaceNet --> Search[å‘é‡ç›¸ä¼¼åº¦æœç´¢]
    
    subgraph VectorSearch["å‘é‡æœç´¢å¼•æ“"]
        ANN["è¿‘ä¼¼æœ€è¿‘é‚»<br/>(ANN)"]
        Threshold["é˜ˆå€¼åˆ¤æ–­<br/>(è·ç¦» < 0.6)"]
    end
    
    Search --> ANN
    ANN --> Threshold
    
    Threshold --> Decision{åŒ¹é…ç»“æœ}
    
    Decision -->|é«˜ç›¸ä¼¼åº¦| Assign[åˆ†é…åˆ°å·²çŸ¥äººç‰©]
    Decision -->|ä½ç›¸ä¼¼åº¦| NewCluster[åˆ›å»ºæ–°äººç‰©èšç±»]
    
    Assign --> UpdateDB[æ›´æ–° Spanner]
    NewCluster --> UpdateDB
    
    UpdateDB --> Notification[æ¨é€é€šçŸ¥<br/>"å‘ç°æ–°äººç‰©"]
    
    Notification --> End([å®Œæˆ])

    style Start fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style End fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style VectorSearch fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style FaceNet fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
```

### 3.2 Cloud Vision API - åœºæ™¯åˆ†æ

**API èƒ½åŠ›**

| åŠŸèƒ½ | è¯´æ˜ | è¿”å›æ•°æ® |
|-----|------|---------|
| **æ ‡ç­¾æ£€æµ‹** | è¯†åˆ«ç‰©ä½“ã€åœºæ™¯ã€æ´»åŠ¨ | æ ‡ç­¾ + ç½®ä¿¡åº¦ |
| **äººè„¸æ£€æµ‹** | æ£€æµ‹äººè„¸åŠè¡¨æƒ… | è¾¹ç•Œæ¡† + æƒ…ç»ª |
| **åœ°æ ‡è¯†åˆ«** | è¯†åˆ«è‘—ååœ°æ ‡ | åœ°æ ‡åç§° + ä½ç½® |
| **OCR** | æå–å›¾åƒæ–‡å­— | æ–‡æœ¬ + ä½ç½® |
| **Logo æ£€æµ‹** | è¯†åˆ«å“ç‰Œ Logo | Logo åç§° |
| **SafeSearch** | ä¸å½“å†…å®¹æ£€æµ‹ | å®‰å…¨ç­‰çº§ |
| **å›¾åƒå±æ€§** | ä¸»è‰²è°ƒåˆ†æ | é¢œè‰² + æ¯”ä¾‹ |
| **Web æ£€æµ‹** | ç›¸ä¼¼å›¾åƒæœç´¢ | ç½‘é¡µ URL |

**API è°ƒç”¨ç¤ºä¾‹**

```python
from google.cloud import vision

def analyze_photo(image_path):
    """è°ƒç”¨ Cloud Vision API åˆ†æç…§ç‰‡"""
    client = vision.ImageAnnotatorClient()
    
    # è¯»å–å›¾åƒ
    with open(image_path, 'rb') as image_file:
        content = image_file.read()
    
    image = vision.Image(content=content)
    
    # æ‰¹é‡è¯·æ±‚å¤šä¸ªç‰¹å¾
    response = client.annotate_image({
        'image': image,
        'features': [
            {'type_': vision.Feature.Type.LABEL_DETECTION, 'max_results': 20},
            {'type_': vision.Feature.Type.FACE_DETECTION},
            {'type_': vision.Feature.Type.LANDMARK_DETECTION},
            {'type_': vision.Feature.Type.IMAGE_PROPERTIES},
            {'type_': vision.Feature.Type.SAFE_SEARCH_DETECTION},
        ]
    })
    
    # è§£æç»“æœ
    results = {
        'labels': [
            {'name': label.description, 'score': label.score}
            for label in response.label_annotations
        ],
        'faces': [
            {
                'bbox': face.bounding_poly,
                'joy': face.joy_likelihood,
                'sorrow': face.sorrow_likelihood,
                'anger': face.anger_likelihood,
                'surprise': face.surprise_likelihood
            }
            for face in response.face_annotations
        ],
        'landmarks': [
            {'name': landmark.description, 'location': landmark.locations[0]}
            for landmark in response.landmark_annotations
        ],
        'dominant_colors': [
            {'color': color.color, 'score': color.score, 'fraction': color.pixel_fraction}
            for color in response.image_properties_annotation.dominant_colors.colors
        ],
        'safe_search': {
            'adult': response.safe_search_annotation.adult,
            'violence': response.safe_search_annotation.violence
        }
    }
    
    return results
```

**æ ‡ç­¾åˆ†ç±»ä½“ç³»**

Vision API ä½¿ç”¨ Google çš„çŸ¥è¯†å›¾è°±ï¼Œè¦†ç›–æ•°ä¸‡ä¸ªç±»åˆ«ã€‚

```
åœºæ™¯åˆ†ç±»ç¤ºä¾‹:
â”œâ”€ è‡ªç„¶ç¯å¢ƒ
â”‚  â”œâ”€ æµ·æ»© (Beach) - 0.95
â”‚  â”œâ”€ æ—¥è½ (Sunset) - 0.89
â”‚  â””â”€ æµ·æ´‹ (Ocean) - 0.87
â”œâ”€ æ´»åŠ¨
â”‚  â”œâ”€ åº¦å‡ (Vacation) - 0.82
â”‚  â””â”€ æ—…è¡Œ (Travel) - 0.78
â”œâ”€ ç‰©ä½“
â”‚  â”œâ”€ å¤©ç©º (Sky) - 0.91
â”‚  â””â”€ æ°´ (Water) - 0.88
â””â”€ ç¾å­¦
   â”œâ”€ é£æ™¯ (Landscape) - 0.85
   â””â”€ è‡ªç„¶ (Nature) - 0.83
```

### 3.3 Cinematic Photos - ç”µå½±æ•ˆæœç”Ÿæˆ

**æŠ€æœ¯åŸç†ï¼šå•ç›®æ·±åº¦ä¼°è®¡**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart LR
    subgraph Input["è¾“å…¥"]
        RGB["2D ç…§ç‰‡<br/>(RGB)"]
    end
    
    subgraph Network["æ·±åº¦ä¼°è®¡ç½‘ç»œ"]
        Encoder["ç¼–ç å™¨<br/>(ResNet)"]
        Decoder["è§£ç å™¨<br/>(UpConv)"]
    end
    
    subgraph Output["è¾“å‡º"]
        DepthMap["æ·±åº¦å›¾<br/>(Depth Map)"]
    end
    
    subgraph Processing["åå¤„ç†"]
        Segmentation["äººç‰©åˆ†å‰²<br/>(DeepLab)"]
        Refine["è¾¹ç•Œä¼˜åŒ–"]
        Parallax["è§†å·®æ˜ å°„"]
    end
    
    subgraph Result["æœ€ç»ˆæ•ˆæœ"]
        Video["3D åŠ¨ç”»è§†é¢‘"]
    end
    
    RGB --> Encoder
    Encoder --> Decoder
    Decoder --> DepthMap
    
    DepthMap --> Segmentation
    Segmentation --> Refine
    Refine --> Parallax
    
    Parallax --> Video

    style Input fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Network fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Processing fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style Result fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
```

**æ·±åº¦ä¼°è®¡ç½‘ç»œæ¶æ„**

```python
class DepthEstimationNetwork(nn.Module):
    """å•ç›®æ·±åº¦ä¼°è®¡ç½‘ç»œ"""
    
    def __init__(self):
        super().__init__()
        
        # ç¼–ç å™¨ï¼šResNet-50 é¢„è®­ç»ƒ
        self.encoder = resnet50(pretrained=True)
        
        # è§£ç å™¨ï¼šä¸Šé‡‡æ ·å±‚
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(2048, 1024, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(1024, 512, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 1, 1)  # è¾“å‡ºå•é€šé“æ·±åº¦å›¾
        )
    
    def forward(self, rgb_image):
        # ç¼–ç 
        features = self.encoder(rgb_image)
        
        # è§£ç 
        depth_map = self.decoder(features)
        
        return depth_map

# æŸå¤±å‡½æ•°ï¼šå°ºåº¦ä¸å˜æŸå¤±
def scale_invariant_loss(pred_depth, gt_depth):
    """
    å°ºåº¦ä¸å˜æŸå¤±å‡½æ•°
    
    å› ä¸ºç”µå½±æ•ˆæœåªéœ€è¦ç›¸å¯¹æ·±åº¦ï¼Œä¸éœ€è¦ç»å¯¹æ·±åº¦
    """
    # å–å¯¹æ•°
    log_pred = torch.log(pred_depth + 1e-6)
    log_gt = torch.log(gt_depth + 1e-6)
    
    # è®¡ç®—å·®å€¼
    diff = log_pred - log_gt
    
    # å°ºåº¦ä¸å˜é¡¹
    loss = torch.mean(diff ** 2) - 0.5 * torch.mean(diff) ** 2
    
    return loss
```

**è®­ç»ƒæ•°æ®ç­–ç•¥**

Google ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†ï¼š

1. **5 æ‘„åƒå¤´é‡‡é›†è£…ç½®**
   - ä¸­å¿ƒç›¸æœº + 4 ä¸ªè¾…åŠ©ç›¸æœº
   - å¤šè§†è§’ç«‹ä½“è§†è§‰ï¼ˆMulti-View Stereoï¼‰
   - ç”ŸæˆçœŸå®æ·±åº¦å›¾

2. **Pixel 4 äººåƒæ¨¡å¼ç…§ç‰‡**
   - åŒæ‘„åƒå¤´ç¡¬ä»¶
   - é«˜è´¨é‡äººç‰©æ·±åº¦
   - çœŸå®åœºæ™¯åˆ†å¸ƒ

**äººç‰©è¾¹ç•Œä¼˜åŒ–**

```python
class PersonBoundaryRefinement:
    """äººç‰©è¾¹ç•Œä¼˜åŒ–"""
    
    def __init__(self):
        # DeepLab äººç‰©åˆ†å‰²æ¨¡å‹ï¼ˆåœ¨ Open Images æ•°æ®é›†è®­ç»ƒï¼‰
        self.segmentation_model = load_deeplab_model()
    
    def refine_depth(self, rgb_image, depth_map):
        # 1. äººç‰©åˆ†å‰²
        person_mask = self.segmentation_model(rgb_image)
        
        # 2. ä¸­å€¼æ»¤æ³¢å¹³æ»‘æ·±åº¦å›¾
        smoothed_depth = median_filter(depth_map, size=5)
        
        # 3. åœ¨äººç‰©è¾¹ç•Œä½¿ç”¨åŸå§‹æ·±åº¦ï¼Œå…¶ä»–åŒºåŸŸä½¿ç”¨å¹³æ»‘æ·±åº¦
        refined_depth = np.where(
            is_near_boundary(person_mask),
            depth_map,  # è¾¹ç•Œä¿æŒé”åˆ©
            smoothed_depth  # å…¶ä»–åŒºåŸŸå¹³æ»‘
        )
        
        return refined_depth
```

**è§†å·®åŠ¨ç”»ç”Ÿæˆ**

```python
def generate_cinematic_video(rgb_image, depth_map, duration=3.0, fps=30):
    """
    ç”Ÿæˆç”µå½±æ•ˆæœè§†é¢‘
    
    Args:
        rgb_image: RGB å›¾åƒ
        depth_map: æ·±åº¦å›¾
        duration: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        fps: å¸§ç‡
    """
    frames = []
    num_frames = int(duration * fps)
    
    for t in range(num_frames):
        # 1. è®¡ç®—ç›¸æœºè¿åŠ¨è½¨è¿¹ï¼ˆKen Burns æ•ˆæœï¼‰
        progress = t / num_frames
        camera_x = np.sin(progress * np.pi) * 20  # æ°´å¹³ç§»åŠ¨
        camera_y = np.cos(progress * np.pi) * 10  # å‚ç›´ç§»åŠ¨
        zoom = 1.0 + progress * 0.1  # è½»å¾®ç¼©æ”¾
        
        # 2. æ ¹æ®æ·±åº¦å›¾è®¡ç®—è§†å·®
        parallax_x = depth_map * camera_x * 0.05
        parallax_y = depth_map * camera_y * 0.05
        
        # 3. åº”ç”¨è§†å·®åç§»
        frame = warp_image(
            rgb_image,
            parallax_x,
            parallax_y,
            zoom
        )
        
        # 4. å¡«å……ç©ºæ´ï¼ˆä½¿ç”¨å‘¨å›´åƒç´ æ’å€¼ï¼‰
        frame = inpaint_holes(frame)
        
        frames.append(frame)
    
    # 5. ç¼–ç ä¸ºè§†é¢‘
    video = encode_video(frames, fps=fps)
    
    return video
```

### 3.4 Gemini - è‡ªç„¶è¯­è¨€æœç´¢

**Ask Photos åŠŸèƒ½**

Google Photos åœ¨ 2024 å¹´å¼•å…¥äº† Gemini é©±åŠ¨çš„è‡ªç„¶è¯­è¨€æœç´¢ã€‚

**æŠ€æœ¯æ¶æ„**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'actorBkg': '#E3F2FD', 'actorBorder': '#1976D2', 'actorTextColor': '#1565C0', 'signalColor': '#1976D2', 'signalTextColor': '#212121', 'noteBkgColor': '#FFF8E1', 'noteBorderColor': '#FFC107'}}}%%
sequenceDiagram
    autonumber
    
    participant User as ç”¨æˆ·
    participant App as Photos App
    participant Gemini as Gemini LLM
    participant Search as æœç´¢å¼•æ“
    participant Spanner as Spanner
    participant Index as å‘é‡ç´¢å¼•

    User->>App: "æˆ‘ä»¬ä¸Šæ¬¡å»ä¼˜èƒœç¾åœ°éœ²è¥åœ¨å“ªï¼Ÿ"
    App->>Gemini: ç†è§£æŸ¥è¯¢æ„å›¾
    
    Gemini->>Gemini: è§£ææŸ¥è¯¢ç»“æ„
    Note over Gemini: å®ä½“: ä¼˜èƒœç¾åœ°<br/>æ´»åŠ¨: éœ²è¥<br/>æ—¶é—´: ä¸Šæ¬¡
    
    Gemini->>Search: ç”Ÿæˆç»“æ„åŒ–æŸ¥è¯¢
    Note over Search: SELECT * FROM photos<br/>WHERE location LIKE '%Yosemite%'<br/>AND labels CONTAINS 'camping'<br/>ORDER BY timestamp DESC
    
    Search->>Spanner: æ‰§è¡Œ SQL æŸ¥è¯¢
    Spanner-->>Search: è¿”å›åŒ¹é…ç…§ç‰‡
    
    Search->>Index: è¯­ä¹‰ç›¸ä¼¼åº¦æ’åº
    Index-->>Search: é‡æ’åºç»“æœ
    
    Search->>Gemini: ç”Ÿæˆå›ç­”
    Gemini->>Gemini: ç†è§£ç…§ç‰‡å†…å®¹
    Note over Gemini: åˆ†æç…§ç‰‡: å¸ç¯·ã€è¥åœ°ã€å±±æ™¯
    
    Gemini-->>App: "2023å¹´7æœˆï¼Œä½ ä»¬åœ¨ Tuolumne Meadows éœ²è¥"
    App-->>User: å±•ç¤ºç…§ç‰‡ + å›ç­”
```

**å¤šæ¨¡æ€åµŒå…¥**

```python
class MultiModalEmbedding:
    """
    å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹ï¼ˆç±»ä¼¼ CLIPï¼‰
    
    å°†å›¾åƒå’Œæ–‡æœ¬æ˜ å°„åˆ°åŒä¸€å‘é‡ç©ºé—´
    """
    
    def __init__(self):
        self.vision_encoder = VisionTransformer()
        self.text_encoder = BERTEncoder()
        self.projection_dim = 512
    
    def encode_image(self, image):
        """ç¼–ç å›¾åƒ"""
        visual_features = self.vision_encoder(image)
        image_embedding = self.project(visual_features)
        return normalize(image_embedding)
    
    def encode_text(self, text):
        """ç¼–ç æ–‡æœ¬"""
        text_features = self.text_encoder(text)
        text_embedding = self.project(text_features)
        return normalize(text_embedding)
    
    def search(self, query_text, photo_database):
        """è¯­ä¹‰æœç´¢"""
        # 1. ç¼–ç æŸ¥è¯¢æ–‡æœ¬
        query_embedding = self.encode_text(query_text)
        
        # 2. è®¡ç®—ä¸æ‰€æœ‰ç…§ç‰‡çš„ç›¸ä¼¼åº¦
        similarities = []
        for photo in photo_database:
            photo_embedding = photo.embedding  # é¢„å…ˆè®¡ç®—
            similarity = cosine_similarity(query_embedding, photo_embedding)
            similarities.append((photo.id, similarity))
        
        # 3. æ’åºè¿”å›
        results = sorted(similarities, key=lambda x: x[1], reverse=True)
        return results[:20]
```

**æŸ¥è¯¢ç†è§£ç¤ºä¾‹**

| ç”¨æˆ·æŸ¥è¯¢ | Gemini ç†è§£ | ç”Ÿæˆçš„æŸ¥è¯¢ |
|---------|-----------|-----------|
| "æˆ‘å’Œ Alice åœ¨ç¬‘çš„ç…§ç‰‡" | äººç‰©: Alice<br/>åŠ¨ä½œ: ç¬‘ | `people='Alice' AND emotion='joy'` |
| "æ¹–è¾¹åˆ’çš®åˆ’è‰‡" | åœ°ç‚¹ç±»å‹: æ¹–<br/>æ´»åŠ¨: åˆ’çš®åˆ’è‰‡ | `scene='lake' AND activity='kayaking'` |
| "æˆ‘åƒçš„æœ€åä¸€é¡¿å¯¿å¸" | ç‰©ä½“: å¯¿å¸<br/>æ—¶é—´: æœ€è¿‘ | `labels='sushi' ORDER BY timestamp DESC LIMIT 1` |

### 3.5 è‡ªåŠ¨è§†é¢‘ç¼–è¾‘

**Memories è§†é¢‘ç”Ÿæˆæµç¨‹**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    Start([è§¦å‘å›å¿†ç”Ÿæˆ]) --> SelectPhotos[é€‰æ‹©ç…§ç‰‡<br/>(æ™ºèƒ½æ’åº)]
    
    SelectPhotos --> ScorePhotos[ç…§ç‰‡è¯„åˆ†]
    
    subgraph Scoring["è¯„åˆ†ç»´åº¦"]
        S1["è´¨é‡åˆ†æ•°"]
        S2["äººç‰©é‡è¦æ€§"]
        S3["å¤šæ ·æ€§"]
        S4["ç¾å­¦åˆ†æ•°"]
    end
    
    ScorePhotos --> Scoring
    Scoring --> Filter[è¿‡æ»¤ Top K<br/>(15-30 å¼ )]
    
    Filter --> ChooseTemplate[é€‰æ‹©æ¨¡æ¿]
    
    subgraph Templates["è§†é¢‘æ¨¡æ¿"]
        T1["æ—…è¡Œ - æ…¢èŠ‚å¥"]
        T2["èšä¼š - å¿«èŠ‚å¥"]
        T3["äººç‰© - æŸ”å’Œ"]
        T4["å›é¡¾ - æ€€æ—§"]
    end
    
    ChooseTemplate --> Templates
    Templates --> MatchMusic[åŒ¹é…éŸ³ä¹]
    
    MatchMusic --> MusicLibrary[éŸ³ä¹åº“<br/>(æŒ‰æƒ…ç»ª/èŠ‚å¥åˆ†ç±»)]
    
    MusicLibrary --> SyncBeats[èŠ‚æ‹åŒæ­¥]
    
    SyncBeats --> Transitions[æ·»åŠ è½¬åœºæ•ˆæœ]
    
    Transitions --> Render[æ¸²æŸ“è§†é¢‘]
    
    Render --> GenerateTitle[ç”Ÿæˆæ ‡é¢˜<br/>(Gemini NLP)]
    
    GenerateTitle --> End([å®Œæˆè§†é¢‘])

    style Start fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style End fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Scoring fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style Templates fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
```

**æ™ºèƒ½ç…§ç‰‡é€‰æ‹©ç®—æ³•**

```python
def select_photos_for_memory(candidate_photos, target_count=20):
    """
    ä¸ºå›å¿†è§†é¢‘æ™ºèƒ½é€‰æ‹©ç…§ç‰‡
    
    å¹³è¡¡è´¨é‡ã€å¤šæ ·æ€§å’Œä»£è¡¨æ€§
    """
    scored_photos = []
    
    for photo in candidate_photos:
        score = 0
        
        # 1. è´¨é‡åˆ†æ•° (0-100)
        quality = photo.quality_score
        score += quality * 0.3
        
        # 2. äººç‰©é‡è¦æ€§ (0-100)
        important_people = sum(
            person.importance_score
            for person in photo.people
        )
        score += important_people * 0.25
        
        # 3. ç¾å­¦åˆ†æ•° (0-100)
        aesthetic = calculate_aesthetic_score(photo)
        score += aesthetic * 0.2
        
        # 4. æƒ…æ„Ÿåˆ†æ•° (å–œæ‚¦ã€æƒŠå–œé«˜åˆ†)
        emotion = max(photo.joy, photo.surprise, 0)
        score += emotion * 0.15
        
        # 5. ç‹¬ç‰¹æ€§ï¼ˆä¸å·²é€‰ç…§ç‰‡çš„å·®å¼‚ï¼‰
        uniqueness = calculate_uniqueness(photo, scored_photos)
        score += uniqueness * 0.1
        
        scored_photos.append((photo, score))
    
    # æ’åºå¹¶é€‰æ‹© Top K
    scored_photos.sort(key=lambda x: x[1], reverse=True)
    selected = [photo for photo, _ in scored_photos[:target_count]]
    
    # æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
    selected.sort(key=lambda x: x.timestamp)
    
    return selected
```

**éŸ³ä¹èŠ‚æ‹åŒæ­¥**

```python
def sync_photos_to_music(photos, music_track):
    """
    å°†ç…§ç‰‡ä¸éŸ³ä¹èŠ‚æ‹åŒæ­¥
    """
    # 1. åˆ†æéŸ³ä¹èŠ‚æ‹
    beats = extract_music_beats(music_track)
    tempo = calculate_tempo(beats)  # BPM (Beats Per Minute)
    
    # 2. è®¡ç®—æ¯å¼ ç…§ç‰‡çš„æ˜¾ç¤ºæ—¶é•¿
    total_duration = music_track.duration
    avg_photo_duration = total_duration / len(photos)
    
    # 3. å¯¹é½åˆ°æœ€è¿‘çš„èŠ‚æ‹
    timeline = []
    current_time = 0
    
    for i, photo in enumerate(photos):
        # æ‰¾åˆ°æœ€è¿‘çš„èŠ‚æ‹ç‚¹
        nearest_beat = find_nearest_beat(current_time, beats)
        
        # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªå…³é”®èŠ‚æ‹çš„æ—¶é•¿
        if i < len(photos) - 1:
            next_beat = find_next_key_beat(nearest_beat, beats, tempo)
            duration = next_beat - nearest_beat
        else:
            duration = music_track.duration - nearest_beat
        
        timeline.append({
            'photo': photo,
            'start_time': nearest_beat,
            'duration': duration,
            'beat_aligned': True
        })
        
        current_time = nearest_beat + duration
    
    return timeline
```

**è½¬åœºæ•ˆæœ**

| è½¬åœºç±»å‹ | é€‚ç”¨åœºæ™¯ | æ•ˆæœæè¿° |
|---------|---------|---------|
| **æ·¡å…¥æ·¡å‡º** | é€šç”¨ | å¹³æ»‘è¿‡æ¸¡ |
| **Ken Burns** | é£æ™¯ç…§ | ç¼©æ”¾ + å¹³ç§» |
| **åˆ’åŠ¨** | è¿ç»­åœºæ™¯ | å·¦å³/ä¸Šä¸‹æ»‘åŠ¨ |
| **ç¼©æ”¾** | ç‰¹å†™ç…§ç‰‡ | æ”¾å¤§/ç¼©å° |
| **æ—‹è½¬** | åŠ¨æ€åœºæ™¯ | 3D æ—‹è½¬ |

---

## å››ã€åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡

### 4.1 å…¨çƒæ¶æ„éƒ¨ç½²

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    subgraph Global["å…¨çƒç”¨æˆ·"]
        NA["åŒ—ç¾ç”¨æˆ·"]
        EU["æ¬§æ´²ç”¨æˆ·"]
        ASIA["äºšæ´²ç”¨æˆ·"]
    end
    
    subgraph LB["å…¨çƒè´Ÿè½½å‡è¡¡"]
        GeoLB["Geo-DNS<br/>(å°±è¿‘æ¥å…¥)"]
    end
    
    subgraph Regions["åŒºåŸŸæ•°æ®ä¸­å¿ƒ"]
        US["us-central1<br/>(ç¾å›½ä¸­éƒ¨)"]
        EUR["europe-west1<br/>(æ¯”åˆ©æ—¶)"]
        AS["asia-east1<br/>(å°æ¹¾)"]
    end
    
    subgraph Services["å¾®æœåŠ¡é›†ç¾¤"]
        Upload["ä¸Šä¼ æœåŠ¡<br/>(æ¯åŒºåŸŸ 100+ å®ä¾‹)"]
        ML["ML æœåŠ¡<br/>(GPU é›†ç¾¤)"]
        API["API æœåŠ¡<br/>(æ— çŠ¶æ€)"]
    end
    
    subgraph Data["å…¨çƒæ•°æ®å±‚"]
        SpannerGlobal["Spanner<br/>(å…¨çƒå‰¯æœ¬)"]
        StorageRegional["Cloud Storage<br/>(åŒºåŸŸå­˜å‚¨)"]
    end
    
    NA --> GeoLB
    EU --> GeoLB
    ASIA --> GeoLB
    
    GeoLB --> US
    GeoLB --> EUR
    GeoLB --> AS
    
    US --> Upload
    EUR --> Upload
    AS --> Upload
    
    Upload --> ML
    ML --> API
    
    API --> SpannerGlobal
    Upload --> StorageRegional
    
    SpannerGlobal -.->|è·¨åŒºåŸŸå¤åˆ¶| US
    SpannerGlobal -.->|è·¨åŒºåŸŸå¤åˆ¶| EUR
    SpannerGlobal -.->|è·¨åŒºåŸŸå¤åˆ¶| AS

    style Global fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Regions fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Data fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
```

### 4.2 å¯é æ€§ä¿éšœ

**SLA ä¿è¯**

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™…è¡¨ç° |
|-----|------|---------|
| **å¯ç”¨æ€§** | 99.95% | 99.999% |
| **ä¸Šä¼ å»¶è¿Ÿ** | < 5s (P95) | 3.2s (P95) |
| **æœç´¢å»¶è¿Ÿ** | < 300ms (P99) | 250ms (P99) |
| **æ•°æ®æŒä¹…æ€§** | 99.999999999% (11 ä¸ª 9) | æ»¡è¶³ |

**å®¹é”™æœºåˆ¶**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    Request([ç”¨æˆ·è¯·æ±‚]) --> Retry[è‡ªåŠ¨é‡è¯•<br/>(æŒ‡æ•°é€€é¿)]
    
    Retry --> CircuitBreaker{ç†”æ–­å™¨}
    
    CircuitBreaker -->|æ­£å¸¸| Service[è°ƒç”¨æœåŠ¡]
    CircuitBreaker -->|å¼‚å¸¸é¢‘ç¹| Fallback[é™çº§ç­–ç•¥]
    
    Service --> Check{æœåŠ¡çŠ¶æ€}
    
    Check -->|æˆåŠŸ| Success([è¿”å›ç»“æœ])
    Check -->|å¤±è´¥| Retry
    Check -->|è¶…æ—¶| Retry
    
    Fallback --> Cache[è¿”å›ç¼“å­˜æ•°æ®]
    Fallback --> Degraded[é™çº§åŠŸèƒ½]
    
    Cache --> PartialSuccess([éƒ¨åˆ†æˆåŠŸ])
    Degraded --> PartialSuccess

    style Request fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Success fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style PartialSuccess fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style CircuitBreaker fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
```

### 4.3 æ€§èƒ½ä¼˜åŒ–

**å¤šå±‚ç¼“å­˜ç­–ç•¥**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart LR
    Request([API è¯·æ±‚]) --> L1[L1: å®¢æˆ·ç«¯ç¼“å­˜<br/>(1 å°æ—¶)]
    
    L1 --> Miss1{ç¼“å­˜å‘½ä¸­?}
    Miss1 -->|å‘½ä¸­| Return1([è¿”å›])
    Miss1 -->|æœªå‘½ä¸­| L2[L2: CDN è¾¹ç¼˜ç¼“å­˜<br/>(5 åˆ†é’Ÿ)]
    
    L2 --> Miss2{ç¼“å­˜å‘½ä¸­?}
    Miss2 -->|å‘½ä¸­| Return2([è¿”å›])
    Miss2 -->|æœªå‘½ä¸­| L3[L3: Memcache<br/>(1 åˆ†é’Ÿ)]
    
    L3 --> Miss3{ç¼“å­˜å‘½ä¸­?}
    Miss3 -->|å‘½ä¸­| Return3([è¿”å›])
    Miss3 -->|æœªå‘½ä¸­| DB[Spanner æ•°æ®åº“]
    
    DB --> Return4([è¿”å› + å¡«å……ç¼“å­˜])

    style Request fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style L1 fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style L2 fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style L3 fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
```

**ç¼“å­˜å‘½ä¸­ç‡**

```
L1 (å®¢æˆ·ç«¯): 80% å‘½ä¸­ç‡
L2 (CDN):    15% å‘½ä¸­ç‡
L3 (Memcache): 4% å‘½ä¸­ç‡
æ•°æ®åº“æŸ¥è¯¢:   1%

æœ‰æ•ˆå»¶è¿Ÿ:
- L1 å‘½ä¸­: 0ms (æœ¬åœ°)
- L2 å‘½ä¸­: 20ms (CDN)
- L3 å‘½ä¸­: 50ms (Memcache)
- DB æŸ¥è¯¢: 250ms (Spanner)

å¹³å‡å»¶è¿Ÿ: 0*0.8 + 20*0.15 + 50*0.04 + 250*0.01 = 7.5ms
```

---

## äº”ã€å®‰å…¨ä¸éšç§

### 5.1 æ•°æ®åŠ å¯†

**å¤šå±‚åŠ å¯†ç­–ç•¥**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    subgraph Client["å®¢æˆ·ç«¯"]
        Upload["ä¸Šä¼ ç…§ç‰‡"]
        TLS["TLS 1.3 åŠ å¯†"]
    end
    
    subgraph Transit["ä¼ è¾“å±‚"]
        HTTPS["HTTPS ä¼ è¾“"]
        Certificate["è¯ä¹¦éªŒè¯"]
    end
    
    subgraph Storage["å­˜å‚¨å±‚"]
        AtRest["é™æ€åŠ å¯†<br/>(AES-256)"]
        KeyRotation["å®šæœŸå¯†é’¥è½®æ¢"]
    end
    
    subgraph Keys["å¯†é’¥ç®¡ç†"]
        KMS["Cloud KMS<br/>(å¯†é’¥ç®¡ç†æœåŠ¡)"]
        HSM["ç¡¬ä»¶å®‰å…¨æ¨¡å—"]
    end
    
    Upload --> TLS
    TLS --> HTTPS
    HTTPS --> Certificate
    
    Certificate --> AtRest
    AtRest --> KeyRotation
    
    KeyRotation --> KMS
    KMS --> HSM

    style Client fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Transit fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Storage fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style Keys fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
```

### 5.2 è®¿é—®æ§åˆ¶

**IAM æƒé™æ¨¡å‹**

```python
class PhotoPermissions:
    """ç…§ç‰‡æƒé™æ§åˆ¶"""
    
    def can_access_photo(self, user, photo):
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒè®¿é—®ç…§ç‰‡"""
        
        # 1. æ‰€æœ‰è€…æ°¸è¿œå¯ä»¥è®¿é—®
        if photo.owner_id == user.id:
            return True
        
        # 2. æ£€æŸ¥ç›¸å†Œåˆ†äº«æƒé™
        for album in photo.albums:
            if album.is_shared_with(user):
                return True
        
        # 3. æ£€æŸ¥å•å¼ ç…§ç‰‡åˆ†äº«
        if photo.is_shared_with(user):
            return True
        
        # 4. æ£€æŸ¥å®¶åº­å…±äº«
        if user.in_family_group(photo.owner):
            return True
        
        return False
    
    def get_user_permissions(self, user, photo):
        """è·å–ç”¨æˆ·å¯¹ç…§ç‰‡çš„æƒé™"""
        permissions = set()
        
        if photo.owner_id == user.id:
            permissions.update(['view', 'edit', 'delete', 'share'])
        elif self.can_access_photo(user, photo):
            share = photo.get_share_info(user)
            if share.can_comment:
                permissions.add('comment')
            if share.can_add_photos:
                permissions.add('contribute')
            permissions.add('view')
        
        return permissions
```

### 5.3 åˆè§„æ€§

**æ•°æ®é©»ç•™ä¸ä¸»æƒ**

| åŒºåŸŸ | æ³•è§„ | Spanner å®ç° |
|-----|------|------------|
| **æ¬§ç›Ÿ** | GDPR | æ•°æ®å­˜å‚¨åœ¨ EU åŒºåŸŸï¼Œè·¨åŒºå¤åˆ¶å¯ç¦ç”¨ |
| **ä¸­å›½** | ç½‘ç»œå®‰å…¨æ³• | æ•°æ®å¿…é¡»å­˜å‚¨åœ¨ä¸­å›½å¢ƒå†… |
| **åŠ å·** | CCPA | ç”¨æˆ·å¯è¯·æ±‚åˆ é™¤æ‰€æœ‰æ•°æ® |

**Spanner æ•°æ®é©»ç•™é…ç½®**

```sql
-- ä¸ºæ¬§ç›Ÿç”¨æˆ·é…ç½®æ•°æ®é©»ç•™
CREATE TABLE eu_users_photos (
    photo_id STRING(36),
    user_id STRING(36),
    -- ... å…¶ä»–å­—æ®µ ...
    PRIMARY KEY (user_id, photo_id)
) PRIMARY KEY (user_id, photo_id),
INTERLEAVE IN PARENT eu_users ON DELETE CASCADE,
ROW DELETION POLICY (OLDER_THAN(timestamp, INTERVAL 7 YEAR));

-- è®¾ç½®å‰¯æœ¬ç­–ç•¥ï¼šä»…åœ¨æ¬§ç›ŸåŒºåŸŸ
ALTER DATABASE photos
SET OPTIONS (
    default_leader = 'europe-west1',
    allowed_readers = ['europe-west1', 'europe-west4']
);
```

---

## å…­ã€æˆæœ¬ä¼˜åŒ–

### 6.1 æˆæœ¬ç»“æ„

**Google Photos è¿è¥æˆæœ¬ä¼°ç®—ï¼ˆå¹´ï¼‰**

| æˆæœ¬é¡¹ | ä¼°ç®— | å æ¯” |
|-------|------|------|
| **å­˜å‚¨æˆæœ¬** | $576M | 45% |
| **è®¡ç®—æˆæœ¬** | $384M | 30% |
| **ç½‘ç»œæˆæœ¬** | $192M | 15% |
| **ML æ¨ç†æˆæœ¬** | $128M | 10% |
| **æ€»è®¡** | **$1.28B** | 100% |

### 6.2 ä¼˜åŒ–ç­–ç•¥

**1. æ™ºèƒ½åˆ†å±‚å­˜å‚¨**

```python
def optimize_storage_class(photo):
    """è‡ªåŠ¨è°ƒæ•´å­˜å‚¨ç±»åˆ«"""
    days_since_upload = (datetime.now() - photo.upload_date).days
    access_count = photo.recent_access_count
    
    if days_since_upload < 30 or access_count > 10:
        return 'STANDARD'  # çƒ­å­˜å‚¨, $0.020/GB/æœˆ
    elif days_since_upload < 90:
        return 'NEARLINE'  # è¿‘çº¿, $0.010/GB/æœˆ
    elif days_since_upload < 365:
        return 'COLDLINE'  # å†·çº¿, $0.004/GB/æœˆ
    else:
        return 'ARCHIVE'   # å½’æ¡£, $0.0012/GB/æœˆ
```

**2. æ‰¹å¤„ç†åˆå¹¶**

```python
# å‡å°‘ Spanner å†™å…¥æ¬¡æ•°
class BatchWriter:
    def __init__(self, batch_size=1000):
        self.batch = []
        self.batch_size = batch_size
    
    def add(self, record):
        self.batch.append(record)
        if len(self.batch) >= self.batch_size:
            self.flush()
    
    def flush(self):
        if self.batch:
            spanner.batch_insert(self.batch)
            self.batch = []

# èŠ‚çœ: 1000 æ¬¡å•ç‹¬å†™å…¥ â†’ 1 æ¬¡æ‰¹é‡å†™å…¥
# æˆæœ¬é™ä½: 90%
```

**3. ML æ¨¡å‹é‡åŒ–**

```python
# å°† Float32 æ¨¡å‹é‡åŒ–ä¸º Int8
quantized_model = tfmodel.quantize(
    model,
    input_type=tf.int8,
    output_type=tf.int8,
    optimization=tf.lite.Optimize.DEFAULT
)

# æ•ˆæœ:
# - æ¨¡å‹å¤§å°: 100MB â†’ 25MB (75% â†“)
# - æ¨ç†é€Ÿåº¦: 2x åŠ é€Ÿ
# - æˆæœ¬: 50% â†“
```

---

## ä¸ƒã€ä¸ Apple ç«¯ä¾§æ–¹æ¡ˆå¯¹æ¯”

### 7.1 æ¶æ„å¯¹æ¯”

| ç»´åº¦ | Google Photos (äº‘ç«¯) | Apple Photos (ç«¯ä¾§) |
|-----|---------------------|-------------------|
| **è®¡ç®—ä½ç½®** | äº‘ç«¯æ•°æ®ä¸­å¿ƒ | è®¾å¤‡æœ¬åœ° |
| **ç®—åŠ›** | æ— é™ï¼ˆå¯æ‰©å±•ï¼‰ | å—é™ï¼ˆè®¾å¤‡æ€§èƒ½ï¼‰ |
| **å»¶è¿Ÿ** | 100-500ms (ç½‘ç»œ) | < 50ms (æœ¬åœ°) |
| **ç¦»çº¿èƒ½åŠ›** | éœ€è¦ç½‘ç»œ | å®Œå…¨ç¦»çº¿ |
| **éšç§** | æ•°æ®ä¸Šä¼ äº‘ç«¯ | æ•°æ®ä¸ç¦»å¼€è®¾å¤‡ |
| **æˆæœ¬** | é«˜ï¼ˆäº‘åŸºç¡€è®¾æ–½ï¼‰ | ä½ï¼ˆç”¨æˆ·è®¾å¤‡ï¼‰ |
| **åŠŸèƒ½å¤æ‚åº¦** | é«˜ï¼ˆNLPã€è§†é¢‘ç”Ÿæˆï¼‰ | ä¸­ï¼ˆå—é™äºè®¾å¤‡ï¼‰ |
| **è·¨è®¾å¤‡åŒæ­¥** | æ— ç¼åŒæ­¥ | éœ€è¦ iCloud |
| **æ¨¡å‹æ›´æ–°** | å³æ—¶ï¼ˆäº‘ç«¯ï¼‰ | éœ€è¦ç³»ç»Ÿæ›´æ–° |

### 7.2 æŠ€æœ¯é€‰å‹å·®å¼‚

| æŠ€æœ¯å±‚é¢ | Google Photos | Apple Photos |
|---------|--------------|--------------|
| **æ•°æ®åº“** | Cloud Spanner (å…¨çƒåˆ†å¸ƒå¼) | SQLite (æœ¬åœ°) |
| **ML æ¡†æ¶** | TensorFlow (äº‘ç«¯) | Core ML (ç«¯ä¾§) |
| **äººè„¸è¯†åˆ«** | FaceNet (128ç»´) | è‡ªå®šä¹‰æ¨¡å‹ (512ç»´æ¨æµ‹) |
| **åœºæ™¯åˆ†æ** | Cloud Vision API (ä¸‡çº§ç±»åˆ«) | ANSA (1000+ ç±»åˆ«) |
| **æ·±åº¦ä¼°è®¡** | äº‘ç«¯ CNN (é«˜ç²¾åº¦) | ç«¯ä¾§ä¼˜åŒ–æ¨¡å‹ |
| **NLP** | Gemini (å¤§æ¨¡å‹) | Foundation Models (å°æ¨¡å‹) |
| **å­˜å‚¨** | Cloud Storage (æ— é™) | è®¾å¤‡å­˜å‚¨ (æœ‰é™) |

### 7.3 ç”¨æˆ·ä½“éªŒå¯¹æ¯”

| åœºæ™¯ | Google Photos | Apple Photos | èƒœè€… |
|-----|--------------|--------------|------|
| **é¦–æ¬¡ä½¿ç”¨** | éœ€ä¸Šä¼ ï¼Œè¾ƒæ…¢ | ç«‹å³å¯ç”¨ | ğŸ† Apple |
| **æœç´¢é€Ÿåº¦** | 300ms (ç½‘ç»œ) | 10ms (æœ¬åœ°) | ğŸ† Apple |
| **åŠŸèƒ½ä¸°å¯Œåº¦** | ç”µå½±æ•ˆæœã€NLPç”Ÿæˆ | åŸºç¡€å›å¿† | ğŸ† Google |
| **éšç§æ„ŸçŸ¥** | ç”¨æˆ·æ‹…å¿§ | å®Œå…¨æ”¾å¿ƒ | ğŸ† Apple |
| **å­˜å‚¨å®¹é‡** | 15GB å…è´¹ + ä»˜è´¹ | 5GB iCloud + ä»˜è´¹ | ğŸ† Google |
| **è·¨å¹³å°** | iOS/Android/Web | ä»… Apple ç”Ÿæ€ | ğŸ† Google |
| **ç¦»çº¿ä½¿ç”¨** | ä¸å¯ç”¨ | å®Œå…¨å¯ç”¨ | ğŸ† Apple |

---

## å…«ã€æœªæ¥æ¼”è¿›æ–¹å‘

### 8.1 æŠ€æœ¯è¶‹åŠ¿

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    Current["å½“å‰æŠ€æœ¯<br/>(2024-2026)"] --> Trend1["ç”Ÿæˆå¼ AI æ·±åŒ–"]
    Current --> Trend2["è¾¹ç¼˜è®¡ç®—"]
    Current --> Trend3["å¤šæ¨¡æ€ç†è§£"]
    Current --> Trend4["å®æ—¶åä½œ"]
    
    Trend1 --> Future1["AI ç”Ÿæˆå®Œæ•´ç›¸å†Œæ•…äº‹"]
    Trend2 --> Future2["è®¾å¤‡+äº‘ç«¯æ··åˆè®¡ç®—"]
    Trend3 --> Future3["è§†é¢‘+éŸ³é¢‘+æ–‡æœ¬èåˆæœç´¢"]
    Trend4 --> Future4["å¤šäººå®æ—¶ç¼–è¾‘å›å¿†"]
    
    Future1 --> Next["ä¸‹ä¸€ä»£<br/>Google Photos"]
    Future2 --> Next
    Future3 --> Next
    Future4 --> Next

    style Current fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Trend1 fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Trend2 fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Trend3 fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Trend4 fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Next fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
```

### 8.2 å¯èƒ½çš„æ¼”è¿›

**1. ç”Ÿæˆå¼ AI æ·±åŒ–**
- AI ç”Ÿæˆå®Œæ•´ç›¸å†Œæ•…äº‹ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ + è§†é¢‘ï¼‰
- æ™ºèƒ½ç…§ç‰‡ä¿®å¤å’Œå¢å¼ºï¼ˆå»æ¨¡ç³Šã€è¶…åˆ†è¾¨ç‡ï¼‰
- é£æ ¼è¿ç§»å’Œè‰ºæœ¯åŒ–å¤„ç†

**2. è¾¹ç¼˜è®¡ç®—èåˆ**
- åœ¨è®¾å¤‡ä¸Šè¿›è¡Œåˆæ­¥åˆ†æï¼ˆé™ä½ä¸Šä¼ é‡ï¼‰
- äº‘ç«¯è¿›è¡Œé«˜çº§å¤„ç†ï¼ˆç”µå½±æ•ˆæœã€NLPï¼‰
- æ™ºèƒ½å†³ç­–ä½•æ—¶ä½¿ç”¨äº‘ç«¯ vs è®¾å¤‡

**3. å¤šæ¨¡æ€ç†è§£å‡çº§**
- è§†é¢‘å†…å®¹æ·±åº¦ç†è§£ï¼ˆåŠ¨ä½œè¯†åˆ«ã€æƒ…èŠ‚ç†è§£ï¼‰
- éŸ³é¢‘åˆ†æï¼ˆå¯¹è¯å†…å®¹ã€èƒŒæ™¯éŸ³ä¹ï¼‰
- è·¨æ¨¡æ€æœç´¢ï¼ˆ"æ‰¾åˆ°æˆ‘è¯´'ç”Ÿæ—¥å¿«ä¹'çš„è§†é¢‘"ï¼‰

**4. å®æ—¶åä½œ**
- å¤šäººåŒæ—¶ç¼–è¾‘å›å¿†è§†é¢‘
- å®æ—¶è¯„è®ºå’Œåé¦ˆ
- åä½œé€‰æ‹©æœ€ä½³ç…§ç‰‡

---

## ä¹ã€å¯¹ Android å¼€å‘çš„å¯ç¤º

### 9.1 æŠ€æœ¯é€‰å‹å»ºè®®

**æ¨èæ¶æ„ï¼šç«¯äº‘æ··åˆ + äº‘ç«¯ä¼˜å…ˆ**

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#E3F2FD', 'primaryTextColor': '#1565C0', 'primaryBorderColor': '#1976D2', 'lineColor': '#546E7A'}}}%%
flowchart TB
    subgraph Client["å®¢æˆ·ç«¯ï¼ˆè½»é‡çº§ï¼‰"]
        Upload["ä¸Šä¼ ç…§ç‰‡"]
        Display["å±•ç¤ºç»“æœ"]
        Cache["æœ¬åœ°ç¼“å­˜"]
    end
    
    subgraph Cloud["äº‘ç«¯ï¼ˆæ ¸å¿ƒå¤„ç†ï¼‰"]
        Storage["å¯¹è±¡å­˜å‚¨<br/>(Minio/S3)"]
        Database["æ•°æ®åº“<br/>(PostgreSQL)"]
        MLService["ML æœåŠ¡<br/>(TensorFlow Serving)"]
        Queue["æ¶ˆæ¯é˜Ÿåˆ—<br/>(RabbitMQ)"]
    end
    
    subgraph Optional["å¯é€‰ç«¯ä¾§"]
        BasicML["åŸºç¡€ ML<br/>(TFLite)"]
        OfflineCache["ç¦»çº¿ç¼“å­˜"]
    end
    
    Upload --> Storage
    Storage --> Queue
    Queue --> MLService
    MLService --> Database
    Database --> Display
    Display --> Cache
    
    BasicML -.->|ç½‘ç»œå·®æ—¶| Upload
    OfflineCache -.->|ç¦»çº¿æ¨¡å¼| Display

    style Client fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style Cloud fill:#E8F5E9,stroke:#388E3C,stroke-width:2px
    style Optional fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
```

### 9.2 æ ¸å¿ƒæŠ€æœ¯æ ˆ

**äº‘ç«¯æŠ€æœ¯æ ˆ**

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | åŸå›  |
|-----|---------|------|
| **æ•°æ®åº“** | PostgreSQL + TimescaleDB | å¼€æºã€æˆç†Ÿã€æ”¯æŒæ—¶åºæ•°æ® |
| **å¯¹è±¡å­˜å‚¨** | MinIO / AWS S3 | æˆæœ¬ä½ã€å¯æ‰©å±• |
| **ML æ¡†æ¶** | TensorFlow Serving | é«˜æ€§èƒ½æ¨ç†æœåŠ¡ |
| **æ¶ˆæ¯é˜Ÿåˆ—** | RabbitMQ / Kafka | å¼‚æ­¥å¤„ç†ã€å‰Šå³°å¡«è°· |
| **ç¼“å­˜** | Redis | é«˜æ€§èƒ½ã€çµæ´» |
| **API ç½‘å…³** | Kong / Nginx | é™æµã€é‰´æƒã€è·¯ç”± |
| **å®¹å™¨ç¼–æ’** | Kubernetes | è‡ªåŠ¨ä¼¸ç¼©ã€é«˜å¯ç”¨ |

**å®¢æˆ·ç«¯æŠ€æœ¯æ ˆ**

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | åŸå›  |
|-----|---------|------|
| **ç½‘ç»œ** | Retrofit + OkHttp | æˆç†Ÿã€ç¨³å®š |
| **å›¾ç‰‡åŠ è½½** | Coil / Glide | é«˜æ€§èƒ½ã€å†…å­˜ä¼˜åŒ– |
| **æ•°æ®åº“** | Room + SQLite | å®˜æ–¹æ¨è |
| **ML (å¯é€‰)** | TensorFlow Lite | ç«¯ä¾§æ¨ç† |
| **ç¼“å­˜** | DiskLruCache | æœ¬åœ°æŒä¹…åŒ– |

### 9.3 å®ç°è·¯çº¿å›¾

**Phase 1: MVP (3-6 ä¸ªæœˆ)**
- âœ… åŸºç¡€ä¸Šä¼ /ä¸‹è½½åŠŸèƒ½
- âœ… äº‘ç«¯å›¾åƒåˆ†æï¼ˆä½¿ç”¨å¼€æºæ¨¡å‹ï¼‰
- âœ… ç®€å•çš„ç›¸å†Œå’Œæ ‡ç­¾
- âœ… åŸºç¡€æœç´¢åŠŸèƒ½

**Phase 2: æ ¸å¿ƒåŠŸèƒ½ (6-12 ä¸ªæœˆ)**
- âœ… äººè„¸è¯†åˆ«å’Œèšç±»
- âœ… åœºæ™¯åˆ†ç±»ï¼ˆ100+ ç±»åˆ«ï¼‰
- âœ… è‡ªåŠ¨å›å¿†ç”Ÿæˆ
- âœ… æ™ºèƒ½ç›¸å†Œæ¨è

**Phase 3: é«˜çº§åŠŸèƒ½ (12+ ä¸ªæœˆ)**
- âœ… ç”µå½±æ•ˆæœç…§ç‰‡
- âœ… è‡ªç„¶è¯­è¨€æœç´¢ï¼ˆé›†æˆå¼€æº LLMï¼‰
- âœ… è‡ªåŠ¨è§†é¢‘ç¼–è¾‘
- âœ… è·¨è®¾å¤‡åŒæ­¥

---

## åã€æ€»ç»“

### 10.1 Google Photos æ ¸å¿ƒä¼˜åŠ¿

| ä¼˜åŠ¿ | è¯´æ˜ |
|-----|------|
| **æ— é™ç®—åŠ›** | äº‘ç«¯åˆ†å¸ƒå¼è®¡ç®—ï¼Œå¤„ç†èƒ½åŠ›æ— ä¸Šé™ |
| **åŠŸèƒ½åˆ›æ–°** | ç”µå½±æ•ˆæœã€Gemini NLPã€è‡ªåŠ¨è§†é¢‘ç¼–è¾‘ |
| **è·¨å¹³å°** | iOS/Android/Web æ— ç¼ä½“éªŒ |
| **æ•°æ®æ°¸ä¹…** | äº‘ç«¯å­˜å‚¨ï¼Œè®¾å¤‡ä¸¢å¤±ä¸å½±å“ |
| **æŒç»­è¿›åŒ–** | äº‘ç«¯æ¨¡å‹æ›´æ–°ï¼Œæ— éœ€å®¢æˆ·ç«¯å‡çº§ |

### 10.2 å…³é”®æŠ€æœ¯è¦ç‚¹

1. **Cloud Spanner** - å…¨çƒä¸€è‡´æ€§åˆ†å¸ƒå¼æ•°æ®åº“ï¼Œçªç ´ CAP å®šç†
2. **FaceNet** - ä¸‰å…ƒç»„æŸå¤±è®­ç»ƒï¼Œ128 ç»´é«˜æ•ˆäººè„¸è¯†åˆ«
3. **æ·±åº¦ä¼°è®¡** - å•ç›® CNN ç”Ÿæˆæ·±åº¦å›¾ï¼Œå®ç°ç”µå½±æ•ˆæœ
4. **Gemini NLP** - å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œè‡ªç„¶è¯­è¨€æœç´¢
5. **Dataflow** - æ‰¹å¤„ç†æµæ°´çº¿ï¼Œæ—¥å¤„ç† 60 äº¿ç…§ç‰‡
6. **åˆ†å±‚å­˜å‚¨** - æ™ºèƒ½é™çº§ï¼Œæˆæœ¬ä¼˜åŒ– 81%

### 10.3 å¯¹ Android å¼€å‘çš„å»ºè®®

**æ ¸å¿ƒåŸåˆ™**
1. âœ… **äº‘ç«¯ä¼˜å…ˆ** - å¤æ‚è®¡ç®—æ”¾äº‘ç«¯ï¼Œå®¢æˆ·ç«¯è½»é‡åŒ–
2. âœ… **å¼‚æ­¥å¤„ç†** - æ¶ˆæ¯é˜Ÿåˆ— + æ‰¹å¤„ç†ï¼Œæå‡ååé‡
3. âœ… **æ™ºèƒ½ç¼“å­˜** - å¤šå±‚ç¼“å­˜ï¼Œé™ä½å»¶è¿Ÿå’Œæˆæœ¬
4. âœ… **å¼€æºä¼˜å…ˆ** - ä½¿ç”¨æˆç†Ÿå¼€æºæ–¹æ¡ˆï¼Œé™ä½å¼€å‘æˆæœ¬
5. âœ… **æ¸è¿›å¢å¼º** - MVP å¿«é€Ÿä¸Šçº¿ï¼Œé€æ­¥æ·»åŠ é«˜çº§åŠŸèƒ½

**æˆæœ¬æ§åˆ¶**
- å¯¹è±¡å­˜å‚¨é€‰æ‹© MinIOï¼ˆè‡ªå»ºï¼‰æˆ– Backblaze B2ï¼ˆä½æˆæœ¬ï¼‰
- ä½¿ç”¨å¼€æº ML æ¨¡å‹ï¼Œé¿å… API è°ƒç”¨è´¹ç”¨
- åˆ†å±‚å­˜å‚¨ + å»é‡ + å‹ç¼©ï¼Œé™ä½å­˜å‚¨æˆæœ¬
- æŒ‰éœ€ä¼¸ç¼©ï¼Œé¿å…èµ„æºé—²ç½®

---

## å‚è€ƒèµ„æ–™

1. [Google Cloud - How Google Photos scaled on Spanner](https://cloud.google.com/blog/products/databases/google-photos-builds-user-experience-on-spanner)
2. [FaceNet: A Unified Embedding for Face Recognition](http://arxiv.org/abs/1503.03832)
3. [Google Research - The Technology Behind Cinematic Photos](https://research.google/blog/the-technology-behind-cinematic-photos/)
4. [Google Cloud Vision API Documentation](https://cloud.google.com/vision/docs)
5. [Spanner, TrueTime and the CAP Theorem](https://research.google/pubs/spanner-truetime-and-the-cap-theorem/)
6. [Google Photos - Ask Photos with Gemini](https://blog.google/products/photos/ask-photos-google-io-2024)

---

> æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0  
> æœ€åæ›´æ–°ï¼š2026-01-28  
> æŠ€æœ¯æ·±åº¦ï¼šâ­â­â­â­â­
